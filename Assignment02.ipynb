{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOH6DBHUsZPYC8OnKwvHXl2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 02 Frequency based audio analysis\n",
        "### Marta Brasola 905305\n"
      ],
      "metadata": {
        "id": "ax76fVeiCFHA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sVXEa9TI-wPG"
      },
      "outputs": [],
      "source": [
        "*# Import packages\n",
        "import os\n",
        "import numpy as np\n",
        "from time import time\n",
        "from scipy.io import wavfile as wav\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd # Notebook only\n",
        "\n",
        "# Classification tools\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# File management\n",
        "from google.colab import drive\n",
        "import tarfile\n",
        "from shutil import copyfile\n",
        "\n",
        "# Frequency analysis\n",
        "from scipy.fft import fft, fftfreq, rfft, rfftfreq\n",
        "from scipy.signal import spectrogram\n",
        "from librosa.feature import melspectrogram, mfcc\n",
        "# from librosa.display import specsho"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement three distinct feature extractors based respectively on Spectrogram, Mel Spectrogram, and MFCC. Consider a single-channel audio signal, and start from the commands shown during the laboratory.\n",
        "\n",
        "Rules:\n",
        "\n",
        "1. Show the effects on classification performance for the dataset \"free-spoken-digit-dataset\" (recordings.tar).\n",
        "2. No feature combination is required for this assignment.\n",
        "3. You can (and should!) use Librosa for the audio description."
      ],
      "metadata": {
        "id": "Ha7cItpoAdBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')\n",
        "tar = tarfile.open('gdrive/MyDrive/Colab Notebooks/Digital Signal/Datasets/recordings.tar')\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "metadata": {
        "id": "f2oikVoMAiF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sound_rate, sound_data = wav.read('recordings/0_jackson_0.wav')\n",
        "print(sound_rate)\n",
        "print(sound_data.shape)"
      ],
      "metadata": {
        "id": "tsNSrTNrA70R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ipd.Audio(sound_data, rate=sound_rate)"
      ],
      "metadata": {
        "id": "KisRautxBAFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sound_time = np.arange(sound_data.shape[0])*1.0/sound_rate\n",
        "plt.plot(sound_time, sound_data)"
      ],
      "metadata": {
        "id": "9kTmYcLlBCaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Placecholder for feature extractor\n",
        "def identity(input):\n",
        "    return input\n",
        "\n",
        "# Data loader\n",
        "def load_data(feature_extractor=identity, normalize=False):\n",
        "\n",
        "    labels = []\n",
        "    features = []\n",
        "\n",
        "    for f in sorted(os.listdir('./recordings')):\n",
        "        if f.endswith('.wav'):\n",
        "            # Load file and compute the requested features\n",
        "            _, signal = wav.read('./recordings/' + f)\n",
        "            cur_features = feature_extractor(signal)\n",
        "            features.append(cur_features)\n",
        "\n",
        "            # Classes\n",
        "            label = f.split('_')[0]\n",
        "            labels.append(label)\n",
        "\n",
        "    # X: features, y: labels\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=1)\n",
        "\n",
        "    if normalize:\n",
        "        eps = 0.001\n",
        "        X_train = np.array(X_train)\n",
        "        X_train_mean = X_train.mean(axis=0)\n",
        "        X_train_std = X_train.std(axis=0)\n",
        "        X_train = (X_train - X_train_mean + eps)/(X_train_std + eps)\n",
        "        X_train = [row for row in X_train]\n",
        "\n",
        "        X_test = [row for row in (np.array(X_test) - X_train_mean + eps)/(X_train_std + eps)]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "gArEHV6PBEAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM with Spectogram\n",
        "\n",
        "### Feature extractor"
      ],
      "metadata": {
        "id": "rxaHf2XjBJeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feats_spectrogram(input, rate=8000, tsize=10):\n",
        "  _, _, spec = spectrogram(input, fs=rate)\n",
        "  output = spec[:, 0:min(spec.shape[1], tsize)]\n",
        "  output = np.pad(output, ((0, 0), (0, tsize-output.shape[1])))\n",
        "  output_flatten = output.flatten()\n",
        "  return output_flatten"
      ],
      "metadata": {
        "id": "m4BFlWGPBExE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = load_data(feature_extractor=feats_spectrogram, normalize=True)"
      ],
      "metadata": {
        "id": "7HmDScSZBOeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters to be tested in cross-validation\n",
        "param_grid = {'C': [100, 500, 1000],\n",
        "          'gamma': [0.005, 0.01, 0.1, 0.5, 1.0], }\n",
        "\n",
        "# Support Vector Machine initialization\n",
        "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid, cv=2)\n",
        "\n",
        "# Training\n",
        "t0 = time()\n",
        "clf = clf.fit(X_train, y_train)\n",
        "print('Training completed in %0.3fs' % (time() - t0))"
      ],
      "metadata": {
        "id": "CAOV5IuzBQUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result of the cross validation for parameters selection\n",
        "print('Best parameters combination:')\n",
        "print(' C: '+str(clf.best_estimator_.C))\n",
        "print(' gamma: '+str(clf.best_estimator_.gamma))"
      ],
      "metadata": {
        "id": "3O7X6lLgBTdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "5Xga-FigBUzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "print('Confusion matrix:')\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.imshow(cm, cmap=plt.cm.Blues);\n",
        "plt.xlabel('Ground truth');\n",
        "plt.ylabel('Prediction');"
      ],
      "metadata": {
        "id": "FErvQtcyBWad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM with Mel Spectogram\n",
        "\n",
        "### Feature extractor"
      ],
      "metadata": {
        "id": "6-ljEIYqBZxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feats_mel(input, rate=8000, tsize=10):\n",
        "  mel = melspectrogram(y=input*1.0, sr=rate)\n",
        "  output = mel[:, 0:min(mel.shape[1], tsize)]\n",
        "  output = np.pad(output, ((0, 0), (0, tsize-output.shape[1])))\n",
        "  output_flatten = output.flatten()\n",
        "  return output_flatten"
      ],
      "metadata": {
        "id": "k_j3BJ4sBeea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = load_data(feature_extractor=feats_mel, normalize=True);"
      ],
      "metadata": {
        "id": "v0MYwBTYBiDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters to be tested in cross-validation\n",
        "param_grid = {'C': [100, 500, 1000],\n",
        "          'gamma': [0.005, 0.01, 0.1, 0.5, 1.0], }\n",
        "\n",
        "# Support Vector Machine initialization\n",
        "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid, cv=2)\n",
        "\n",
        "# Training\n",
        "t0 = time()\n",
        "clf = clf.fit(X_train, y_train)\n",
        "print('Training completed in %0.3fs' % (time() - t0))"
      ],
      "metadata": {
        "id": "EDIR_Km_BjWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result of the cross validation for parameters selection\n",
        "print('Best parameters combination:')\n",
        "print(' C: '+str(clf.best_estimator_.C))\n",
        "print(' gamma: '+str(clf.best_estimator_.gamma))"
      ],
      "metadata": {
        "id": "po6ZVY1yBlYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "pLOfD2AABmm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "print('Confusion matrix:')\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.imshow(cm, cmap=plt.cm.Blues);\n",
        "plt.xlabel('Ground truth');\n",
        "plt.ylabel('Prediction');"
      ],
      "metadata": {
        "id": "gFejzaEtBoAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM with MFCC\n",
        "\n",
        "### Feature extractor"
      ],
      "metadata": {
        "id": "_TsFJW_PBrHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feats_mfcc(input, rate=8000, tsize=10):\n",
        "  mfccs = mfcc(input*1.0, sr=rate)\n",
        "  output = mfccs[:, 0:min(mfccs.shape[1], tsize)]\n",
        "  output = np.pad(output, ((0, 0), (0, tsize-output.shape[1])))\n",
        "  output_flatten = output.flatten()\n",
        "  return output_flatten"
      ],
      "metadata": {
        "id": "AEu7R1hlBvZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = load_data(feature_extractor=feats_mfcc, normalize=True);"
      ],
      "metadata": {
        "id": "iMvF-a0mB04r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters to be tested in cross-validation\n",
        "param_grid = {'C': [100, 500, 1000],\n",
        "          'gamma': [0.005, 0.01, 0.1, 0.5, 1.0], }\n",
        "\n",
        "# Support Vector Machine initialization\n",
        "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid, cv=2)\n",
        "\n",
        "# Training\n",
        "t0 = time()\n",
        "clf = clf.fit(X_train, y_train)\n",
        "print('Training completed in %0.3fs' % (time() - t0))"
      ],
      "metadata": {
        "id": "LEvKb8ogB2bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result of the cross validation for parameters selection\n",
        "print('Best parameters combination:')\n",
        "print(' C: '+str(clf.best_estimator_.C))\n",
        "print(' gamma: '+str(clf.best_estimator_.gamma))"
      ],
      "metadata": {
        "id": "oiJdP2eVB4M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "IZqFCy9ZB5af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "print('Confusion matrix:')\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.imshow(cm, cmap=plt.cm.Blues);\n",
        "plt.xlabel('Ground truth');\n",
        "plt.ylabel('Prediction');"
      ],
      "metadata": {
        "id": "RS5HqEOhB8bb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}